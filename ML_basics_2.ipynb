{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_basics_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPAg62PBwwqyUwdA+NFhsOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MrocznyKapelusz/ML_basics/blob/master/ML_basics_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVF2fXYFzi_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8BIL6dM1CNK",
        "colab_type": "text"
      },
      "source": [
        "Dołączamy dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QT8VgUIz4cW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd7bfc75-8c88-42e5-ad41-85b5ebe0a3d2"
      },
      "source": [
        "mnist =tf.keras.datasets.fashion_mnist\n",
        "print(type(mnist))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'module'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHC6bNQl04Lg",
        "colab_type": "text"
      },
      "source": [
        "2 zestawy po 2 listy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q_xzMwz0XJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c315e142-1735-43fd-d6da-eeba587e8a32"
      },
      "source": [
        "(training_images, training_labels),(test_images,test_labels)=mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmGE5I-j6hGr",
        "colab_type": "text"
      },
      "source": [
        "zobacz przykładowy training img i label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyZBmzuS13yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0a9b6e3c-669e-422d-a98d-de30cf304b11"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[42])\n",
        "print(training_labels[42])\n",
        "print(training_images[42])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  82 187\n",
            "   26   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 179 240 237\n",
            "  255 240 139  83  64  43  60  54   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   1   0   0   1   0  58 239 222 234\n",
            "  238 246 252 254 255 248 255 187   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   2   3   0   0 194 239 226 237\n",
            "  235 232 230 234 234 233 249 171   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   1   1   0   0  10 255 226 242 239\n",
            "  238 239 240 239 242 238 248 192   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0 172 245 229 240 241\n",
            "  240 241 243 243 241 227 250 209   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   6   5   0  62 255 230 236 239 241\n",
            "  242 241 242 242 238 238 242 253   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3   0   0 255 235 228 244 241 241\n",
            "  244 243 243 244 243 239 235 255  22   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 246 228 220 245 243 237 241\n",
            "  242 242 242 243 239 237 235 253 106   0]\n",
            " [  0   0   3   4   4   2   1   0   0  18 243 228 231 241 243 237 238 242\n",
            "  241 240 240 240 235 237 236 246 234   0]\n",
            " [  1   0   0   0   0   0   0   0  22 255 238 227 238 239 237 241 241 237\n",
            "  236 238 239 239 239 239 239 237 255   0]\n",
            " [  0   0   0   0   0  25  83 168 255 225 225 235 228 230 227 225 227 231\n",
            "  232 237 240 236 238 239 239 235 251  62]\n",
            " [  0 165 225 220 224 255 255 233 229 223 227 228 231 232 235 237 233 230\n",
            "  228 230 233 232 235 233 234 235 255  58]\n",
            " [ 52 251 221 226 227 225 225 225 226 226 225 227 231 229 232 239 245 250\n",
            "  251 252 254 254 252 254 252 235 255   0]\n",
            " [ 31 208 230 233 233 237 236 236 241 235 241 247 251 254 242 236 233 227\n",
            "  219 202 193 189 186 181 171 165 190  42]\n",
            " [ 77 199 172 188 199 202 218 219 220 229 234 222 213 209 207 210 203 184\n",
            "  152 171 165 162 162 167 168 157 192  78]\n",
            " [  0  45 101 140 159 174 182 186 185 188 195 197 188 175 133  70  19   0\n",
            "    0 209 231 218 222 224 227 217 229  93]\n",
            " [  0   0   0   0   0   0   2  24  37  45  32  18  11   0   0   0   0   0\n",
            "    0  72  51  53  37  34  29  31   5   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj-aKQEE6sli",
        "colab_type": "text"
      },
      "source": [
        "NOrmalizacja listy - zamiast 0-255 będzie 0-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSGP2h6f6fjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images = training_images / 255.0\n",
        "test_images=test_images / 255.0\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5VzXWpD8HI3",
        "colab_type": "text"
      },
      "source": [
        "#Projekt modelu NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3kRi7wq8MSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10,activation=tf.nn.softmax)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuyxruIu8-7_",
        "colab_type": "text"
      },
      "source": [
        "**Sequential** - sekwencja warstw w \n",
        "\n",
        "**Flatten** - zmienia obrazek w set (1 wymiarowy)\n",
        "\n",
        "**Dense** - dodaje warstwy neuronow. Kazda warstwa potrzebuje funkcji aktywacyjnej, ktora mowi co warstwa ma robic.\n",
        "\n",
        "**Relu** - jesli x>0 return x, else return 0 - do kolejnej warstwy przekazuje tylko wartosci wieksze niz 0\n",
        "\n",
        "**Softmax** - zeruje nienajwieksze wartosci w zbiorze, a najwieksza = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7d7gNYb-vCg",
        "colab_type": "text"
      },
      "source": [
        "# Budowa modelu\n",
        "\n",
        "a potem jego szkolenie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_cJhM9l8rUd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a816e3db-6b80-4e1a-a3bc-4b19fef032c4"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels,epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2819 - accuracy: 0.8956\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2678 - accuracy: 0.9010\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2569 - accuracy: 0.9052\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2487 - accuracy: 0.9076\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2390 - accuracy: 0.9116\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f5b576a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h4Ati6u_hQz",
        "colab_type": "text"
      },
      "source": [
        "# Sprawdzenie na nowych danych"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb7gpS24_ex1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d7af37b6-bf30-44e8-a899-5c3ab16ced89"
      },
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3316 - accuracy: 0.8837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3315736651420593, 0.8837000131607056]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_dDWEFKCKcs",
        "colab_type": "text"
      },
      "source": [
        "Ex.1:\n",
        "\n",
        "Sprawdzamy jaka kategorie przydziela dla pierwszego obrazka - dla accuracy 88% z evaluate - przewiduje 9 - czyli tak, jak powinno byc (label dla 0-wego elementu to tez 9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgjbPQwlCNpn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c03bd772-2c7a-4206-cfa7-5c5c516905ab"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.3448553e-08 7.7741598e-12 8.9954592e-11 3.8422741e-09 3.5825801e-10\n",
            " 2.6919423e-03 7.0597483e-09 1.1624555e-02 1.4363070e-08 9.8568350e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYDC5FImCZVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "415f3790-c2ca-49ac-94a1-a3e54a683834"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ6OmYp_EjxP",
        "colab_type": "text"
      },
      "source": [
        "EX 2:\n",
        "\n",
        "Nowe wartosci dla gestosci warstw"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2g1YLnUEjLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "ea8270fa-5c45-48f9-e290-61c1e1731470"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.4702\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3566\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.3231\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.2977\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2791\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3283\n",
            "[2.1426645e-07 7.2437647e-09 1.1575138e-10 2.0932751e-09 2.7369234e-09\n",
            " 4.1565071e-03 8.5387299e-08 6.7626396e-03 2.6615115e-08 9.8908055e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sfwb0kZF0To",
        "colab_type": "text"
      },
      "source": [
        "EX 3:\n",
        "\n",
        "Co gdyby nie bylo Flatten()?\n",
        "\n",
        "Pierwsza warstwa NN powinna byc tego samego ksztaltu co dane (28x28 zmieniamy na 784x1)\n",
        "\n",
        "\n",
        "EX 4:\n",
        "Co gdyby ostatnich warstw nie bylo 10, tylko na przyklad 5? \n",
        "Blad! Liczba neuronow w ostatniej warstwie powinna byc rowna liczbie klas, ktore przydzielamy (0-9 u nas, czyli jest ich 10)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l63-aWyF5vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a3c0f29f-cb85-4fa2-fb56-711785d332a3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
        "# model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "\n",
        "# This is the version with the wrong number of neurons in the final layer\n",
        "# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "#                                     tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "#                                     tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.5172\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3938\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3540\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3322\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3141\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3597\n",
            "[5.08060521e-06 1.51445789e-08 1.29366720e-06 2.01265775e-05\n",
            " 6.29883289e-07 4.29475531e-02 7.55200244e-06 1.10716775e-01\n",
            " 3.37817683e-03 8.42922866e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS_3FkKZHNMW",
        "colab_type": "text"
      },
      "source": [
        "EX 5:\n",
        "Co gdy dodasz dodatkowa warstwe pomiedzy?\n",
        "\n",
        "Bez wielkiej roznicy - ze wzgledu na dosc latwe dane"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xP9mx5ZeHtO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "f48a361f-d8c7-4579-92b8-2bd025e97304"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4697\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3575\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3204\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2958\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2764\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3388\n",
            "[5.2169858e-06 1.0393775e-05 5.5649944e-06 3.5218989e-06 2.1743340e-06\n",
            " 2.5578854e-03 2.5303945e-05 4.5238622e-02 2.0924467e-06 9.5214921e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1ywae_QH78p",
        "colab_type": "text"
      },
      "source": [
        "EX 6:\n",
        "\n",
        "Wiecej epok\n",
        "\n",
        "Zjawisko \"overfittingu\" (przetrenowania?) - gdy NN trenuje za duzo, loss wcale nie spada, a nawet moze zaczac rosnac\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE3esj9BURQe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "36775433-d5d7-4418-c140-2df7534d2b6d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=15)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5001 - accuracy: 0.8254\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3749 - accuracy: 0.8647\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3370 - accuracy: 0.8777\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3142 - accuracy: 0.8845\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2951 - accuracy: 0.8924\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2818 - accuracy: 0.8957\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2714 - accuracy: 0.9001\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2591 - accuracy: 0.9030\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2498 - accuracy: 0.9076\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2414 - accuracy: 0.9094\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2308 - accuracy: 0.9137\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2253 - accuracy: 0.9156\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2175 - accuracy: 0.9192\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2121 - accuracy: 0.9207\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2066 - accuracy: 0.9223\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3458 - accuracy: 0.8829\n",
            "[1.7785971e-11 5.4256864e-20 1.5904963e-16 1.9833762e-20 2.1577871e-11\n",
            " 6.5033314e-15 2.1959273e-18 9.1364274e-14 1.0000000e+00 3.1102573e-21]\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shYB_MZ1JbeE",
        "colab_type": "text"
      },
      "source": [
        "EX 7:\n",
        "\n",
        "Bez normalizacji danych - pierwsza epoka ma ogromny loss, ale koncowy wynik jest ok\n",
        "\n",
        "Normalizacja zapewnia, ze kazdy z feature'ow pojedynczej danej jest tak samo wazny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDqNAqrpCNg0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "e6fbe40a-f08f-4b58-a79b-a9e9136740a3"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# To experiment with removing normalization, comment out the following 2 lines\n",
        "# training_images=training_images/255.0\n",
        "# test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 3.8385 - accuracy: 0.7571\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5467 - accuracy: 0.8146\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5190 - accuracy: 0.8223\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.5146 - accuracy: 0.8248\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4941 - accuracy: 0.8351\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5074 - accuracy: 0.8346\n",
            "[8.87161304e-21 9.48696292e-22 3.94841133e-28 6.22786910e-24\n",
            " 1.23225689e-26 1.19569175e-01 1.95335503e-26 1.61739124e-03\n",
            " 1.93946537e-16 8.78813386e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vt3Gz7-LOlt",
        "colab_type": "text"
      },
      "source": [
        "EX 8:\n",
        "\n",
        "Zatrzymanie treningu po osiagnieciu wystarczajacej (okreslonej) celnosci."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjqK-nRaLs2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SGKqB_i8LtQs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "f515ec15-c47d-4288-8747-3d4650c16b25"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4753 - accuracy: 0.8299\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3589 - accuracy: 0.8677\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3231 - accuracy: 0.8802\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2976 - accuracy: 0.8898\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2787 - accuracy: 0.8972\n",
            "Epoch 6/10\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.2653 - accuracy: 0.9010\n",
            "Reached 90% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2652 - accuracy: 0.9010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f54e86c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}